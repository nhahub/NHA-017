{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7b6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9338d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"RawToBronze_Cleaning_bayut\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f57059f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------+-----------+------+--------+--------+---------+----------+----------+\n",
      "|               title|                 url|   price|currency|   location|region|size_sqm|bedrooms|bathrooms|  latitude| longitude|\n",
      "+--------------------+--------------------+--------+--------+-----------+------+--------+--------+---------+----------+----------+\n",
      "|Chalet for Sale â€“...|https://www.bayut...|26500000|     EGP|North Coast|Matruh|     130|       2|        2|30.9628937|28.7565892|\n",
      "|Chalet for sale i...|https://www.bayut...|32000000|     EGP|North Coast|Matruh|     189|       3|        3|30.9628937|28.7565892|\n",
      "|Apartment ready t...|https://www.bayut...|13000000|     EGP|  New Cairo| Cairo|     191|       3|        3|29.9637831|31.5383442|\n",
      "+--------------------+--------------------+--------+--------+-----------+------+--------+--------+---------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- size_sqm: string (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"hdfs://namenode:9000/datalake/bronze/bayutData\")\n",
    "df.show(3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7267b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 1903\n",
      "Distinct Rows: 1903\n",
      "Duplicate Rows Found: 0\n"
     ]
    }
   ],
   "source": [
    "total_rows = df.count()\n",
    "distinct_rows = df.distinct().count()\n",
    "\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Distinct Rows: {distinct_rows}\")\n",
    "print(f\"Duplicate Rows Found: {total_rows - distinct_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa6ab663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+--------+--------+------+--------+--------+---------+--------+---------+\n",
      "|title|url|price|currency|location|region|size_sqm|bedrooms|bathrooms|latitude|longitude|\n",
      "+-----+---+-----+--------+--------+------+--------+--------+---------+--------+---------+\n",
      "|    0|  0|    0|       0|       0|     0|       0|       0|        0|       0|        0|\n",
      "+-----+---+-----+--------+--------+------+--------+--------+---------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    [sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "     for c in df.columns]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24acd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, when\n",
    "\n",
    "from pyspark.sql.functions import col, lower, when\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"property_type\",\n",
    "    when(lower(col(\"title\")).like(\"%apartment%\") | lower(col(\"title\")).like(\"%apt%\") | lower(col(\"title\")).contains(\"apartm\"), \"Apartment\")\n",
    "    .when(lower(col(\"title\")).like(\"%townhouse%\")  | lower(col(\"title\")).contains(\"town\") | lower(col(\"title\")).like(\"%town house%\"),\"Townhouse\")\n",
    "    .when(lower(col(\"title\")).like(\"%twin house%\") | lower(col(\"title\")).like(\"%twin%\"), \"Twin House\")\n",
    "    .when(lower(col(\"title\")).like(\"%villa%\"), \"Villa\")\n",
    "    .when(lower(col(\"title\")).like(\"%ivilla%\"), \"iVilla\")\n",
    "    .when(lower(col(\"title\")).like(\"%hotel apartment%\"), \"Hotel Apartment\")\n",
    "    .when(lower(col(\"title\")).like(\"%penthouse%\"), \"Penthouse\")\n",
    "    .when(lower(col(\"title\")).like(\"%land%\"), \"Land\")\n",
    "    .when(lower(col(\"title\")).like(\"%chalet%\") | lower(col(\"title\")).like(\"%chaleat%\"), \"Chalet\")\n",
    "    .when(lower(col(\"title\")).like(\"%palace%\"), \"Palace\")\n",
    "    .when(lower(col(\"title\")).like(\"%mansion%\"), \"Mansion\")\n",
    "    .when(lower(col(\"title\")).like(\"%duplex%\") | lower(col(\"title\")).like(\"%dublex%\"), \"Duplex\")\n",
    "    .when(lower(col(\"title\")).like(\"%bungalow%\"), \"Bungalow\")\n",
    "    .when(lower(col(\"title\")).like(\"%studio%\"), \"Studio\")\n",
    "    .when(lower(col(\"title\")).like(\"%roof%\"), \"Roof\")\n",
    "    .when(lower(col(\"title\")).like(\"%triplex%\"), \"Triplex\")\n",
    "    .when(lower(col(\"title\")).like(\"%standalone%\") | lower(col(\"title\")).like(\"%stand-alone%\") | lower(col(\"title\")).contains(\"stand\"), \"Standalone\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "585d330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "other_apartments = df.filter((col(\"property_type\")==\"Other\"))\n",
    "#other_apartments.show(5)\n",
    "other_apartments.toPandas().to_csv(\"/data/other_apartmentss.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a7818c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"property_type\")==\"Other\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f1b4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim\n",
    "\n",
    "# 1. Drop duplicate rows\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# 2. Trim spaces from string columns\n",
    "for c in df.columns:\n",
    "    df = df.withColumn(c, trim(col(c)))\n",
    "\n",
    "# 3. Drop columns that are fully null\n",
    "non_empty_cols = [c for c in df.columns if df.filter(col(c).isNotNull()).count() > 0]\n",
    "df = df.select(non_empty_cols)\n",
    "\n",
    "df = df.na.drop(subset=[\"title\", \"property_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eac01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"currency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c6c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- size_sqm: double (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- bathrooms: integer (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- property_type: string (nullable = false)\n",
      "\n",
      "+--------------------+--------------------+--------+--------------+------+--------+--------+---------+---------------+---------------+-------------+\n",
      "|               title|                 url|   price|      location|region|size_sqm|bedrooms|bathrooms|       latitude|      longitude|property_type|\n",
      "+--------------------+--------------------+--------+--------------+------+--------+--------+---------+---------------+---------------+-------------+\n",
      "|for sale chalet w...|https://www.bayut...| 6150000|    ain sukhna|  suez|   160.0|       4|        3|      29.748365|      32.401061|       chalet|\n",
      "|last finished apa...|https://www.bayut...| 8000000|  sheikh zayed|  giza|   200.0|       3|        3|30.073028969307|30.965373520242|    apartment|\n",
      "|palace from owner...|https://www.bayut...|90000000|     new cairo| cairo|  1300.0|       7|        8|       30.01321|       31.48737|       palace|\n",
      "|duplex apartment ...|https://www.bayut...| 3700000|new heliopolis| cairo|    50.0|       1|        1|       30.16528|       31.68815|    apartment|\n",
      "|luxury penthouse ...|https://www.bayut...|28652143|     new cairo| cairo|   300.0|       4|        3|     29.9875186|     31.5555302|    penthouse|\n",
      "+--------------------+--------------------+--------+--------------+------+--------+--------+---------+---------------+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, trim, lower\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# Numeric cleanup and casting\n",
    "numeric_cols = {\n",
    "    \"price\": IntegerType(),\n",
    "    \"size_sqm\": DoubleType(),\n",
    "    \"bedrooms\": IntegerType(),\n",
    "    \"bathrooms\": IntegerType(),\n",
    "    \"latitude\": DoubleType(),\n",
    "    \"longitude\": DoubleType()\n",
    "}\n",
    "\n",
    "for col_name, dtype in numeric_cols.items():\n",
    "    df = (\n",
    "        df.withColumn(col_name,\n",
    "            regexp_replace(col(col_name), \"[^0-9.-]\", \"\")  # remove non-numeric chars\n",
    "            .cast(dtype)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Normalize string columns: trim + lowercase for uniformity\n",
    "string_cols = [\"title\", \"url\",  \"location\", \"region\", \"property_type\"]\n",
    "for col_name in string_cols:\n",
    "    df = df.withColumn(col_name, trim(lower(col(col_name))))\n",
    "\n",
    "# Drop rows with invalid critical data (like missing property_type or price)\n",
    "df = df.na.drop(subset=[\"property_type\", \"price\", \"location\"])\n",
    "\n",
    "# Optional: remove duplicates\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# Reorder columns nicely\n",
    "df = df.select(\n",
    "    \"title\", \"url\", \"price\", \"location\", \"region\",\n",
    "    \"size_sqm\", \"bedrooms\", \"bathrooms\", \"latitude\", \"longitude\", \"property_type\"\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99e5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/cleaned_bayut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "648e89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs dfs -rm /datalake/silver/cleaned_bayut/_SUCCESS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
